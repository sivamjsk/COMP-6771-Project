{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Necessary Code Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import tensorflow\n",
    "import keras\n",
    "import visualkeras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Concatenate, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.layers import MaxPooling2D, Input, Conv2D, UpSampling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "## print(\"Done importing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Static code variables declarations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_name = \"awb\"\n",
    "# Size of the training images to be set before training\n",
    "img_size = 256\n",
    "\n",
    "#Array declartions for train/test images along with groung truth images\n",
    "train_images = []\n",
    "ground_truth_images = []\n",
    "use_saved_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collect images  - Iterate over folder to obtain images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path=r\"images/Bad\"\n",
    "counter_train_image = 0;\n",
    "for image in os.listdir(path):\n",
    "    # filteration to avoid hidden file added by MacOS\n",
    "    if (image != \".DS_Store\"):\n",
    "        # Repeatedly iterate the folder to obtain all images\n",
    "        imgages = cv2.imread(os.path.join(path,image) ,cv2.IMREAD_COLOR)\n",
    "        # Resize the images for normalization\n",
    "        train_images_array = cv2.resize(imgages, (img_size, img_size))\n",
    "        train_images.append(train_images_array)\n",
    "        print(\"Saved train color image :\",counter_train_image)\n",
    "        counter_train_image+=1\n",
    "\n",
    "\n",
    "path=r\"images/Good\"\n",
    "counter_ground_image = 0;\n",
    "for image in os.listdir(path):\n",
    "    # filteration to avoid hidden file added by MacOS\n",
    "    if (image != \".DS_Store\"):\n",
    "        # Repeatedly iterate the folder to obtain all images\n",
    "        imgages = cv2.imread(os.path.join(path,image) ,cv2.IMREAD_COLOR)\n",
    "        # Resize the images for normalization\n",
    "        ground_images_array = cv2.resize(imgages, (img_size, img_size))\n",
    "        ground_truth_images.append(ground_images_array)\n",
    "        print(\"Saved ground image :\",counter_ground_image)\n",
    "        counter_ground_image+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalization of the images and splitting them for train and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the folder containing the images\n",
    "folder_path = \"/Users/sivakumaran/Downloads/IP/COMP-6771-Project/images/Test\"\n",
    "\n",
    "# Load all image files in the folder\n",
    "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# Load the first 10 images\n",
    "images = [plt.imread(f) for f in image_files[:10]]\n",
    "\n",
    "# Create a new figure with a grid layout\n",
    "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(10, 5))\n",
    "\n",
    "# Display the images in the grid\n",
    "for i, im in enumerate(images):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    axs[row, col].imshow(im)\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "# Show the grid in the console\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_images = (np.array(train_images))/255\n",
    "ground_truth_images = (np.array(ground_truth_images))/255\n",
    "train_image_for_train, train_image_for_test, ground_truth_train, ground_truth_test = train_test_split(train_images, ground_truth_images, test_size=0.2)\n",
    "#print(len(train_image_for_train))\n",
    "#print(len(train_image_for_test))\n",
    "#print(len(ground_truth_train))\n",
    "#print(len(ground_truth_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = {'0':len(train_image_for_train), \"1\":len(train_image_for_test), '2':len(ground_truth_train),\"3\":len(ground_truth_test)}\n",
    "images = list(data.keys())\n",
    "values = list(data.values())\n",
    "plt.bar(images, values, color ='maroon',width = 0.4)\n",
    "plt.xlabel(\"image split\")\n",
    "plt.ylabel(\"No. of images\")\n",
    "plt.title(\"Number of images for train/test\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Legend\\n\")\n",
    "print(\"0 - train_image_for_train \",len(train_image_for_train))\n",
    "print(\"1 - train_image_for_test \",len(train_image_for_test))\n",
    "print(\"2 - ground_truth_train \",len(ground_truth_train))\n",
    "print(\"3 - ground_truth_test \",len(ground_truth_test))\n",
    "\n",
    "labels = 'Training', 'Testing'\n",
    "\n",
    "sizes = [len(train_image_for_train) + len(ground_truth_train), len(train_image_for_test) + len(ground_truth_test)]\n",
    "explode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct=\"%1.1f%%\",\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.title(\"Divison of data\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Total Data set Size: \",len(train_image_for_train) + len(ground_truth_train) + len(train_image_for_test) + len(ground_truth_test))\n",
    "print(\"Train Image Size : \",len(train_image_for_train) + len(ground_truth_train) )\n",
    "print(\"Test Image Size : \",len(train_image_for_test) + len(ground_truth_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convolution Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(256, 256, 3), name=\"Main Input\")\n",
    "\n",
    "# Define the encoder layers\n",
    "encoder_inc = Conv2D(24, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name=\"encoder_inc\")(input_layer)\n",
    "encoder_down1 = Conv2D(48, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', name=\"encoder_down1\")(encoder_inc)\n",
    "encoder_down2 = Conv2D(96, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', name=\"encoder_down2\")(encoder_down1)\n",
    "encoder_down3 = Conv2D(192, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', name=\"encoder_down3\")(encoder_down2)\n",
    "\n",
    "# Define the bridge layers\n",
    "encoder_bridge_down = Conv2D(384, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', name=\"encoder_bridge_down\")(encoder_down3)\n",
    "encoder_bridge_up = Conv2DTranspose(192, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', name=\"encoder_bridge_up\")(encoder_bridge_down)\n",
    "\n",
    "#Define the decoder layers\n",
    "print(encoder_down3, encoder_bridge_up)\n",
    "concatenate_8 = Concatenate()([encoder_down3, encoder_bridge_up])\n",
    "sequential_8 = Sequential([\n",
    "    Conv2D(192, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(192, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(192, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')\n",
    "], name=\"sequential_8\")(concatenate_8)\n",
    "conv2d_transpose_9 = Conv2DTranspose(96, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', name=\"conv2d_transpose_9\")(sequential_8)\n",
    "\n",
    "concatenate_9 = Concatenate()([encoder_down2, conv2d_transpose_9])\n",
    "sequential_9 = Sequential([\n",
    "    Conv2D(96, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(96, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(96, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')\n",
    "], name=\"sequential_9\")(concatenate_9)\n",
    "conv2d_transpose_10 = Conv2DTranspose(48, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', name=\"conv2d_transpose_10\")(sequential_9)\n",
    "\n",
    "concatenate_10 = Concatenate()([encoder_down1, conv2d_transpose_10])\n",
    "sequential_10 = Sequential([\n",
    "    Conv2D(48, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(48, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(48, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')\n",
    "], name=\"sequential_10\")(concatenate_10)\n",
    "conv2d_transpose_11 = Conv2DTranspose(24, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu', name=\"conv2d_transpose_11\")(sequential_10)\n",
    "\n",
    "concatenate_11 = Concatenate()([input_layer, conv2d_transpose_11])\n",
    "sequential_11 = Sequential([\n",
    "    Conv2D(3, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(3, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(3, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')\n",
    "], name=\"sequential_11\")(concatenate_11)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=sequential_11)\n",
    "model.compile(optimizer='Adam', loss='mse',metrics=['accuracy','MeanSquaredError','mae', 'mape'])\n",
    "if use_saved_model:\n",
    "    model = keras.models.load_model(\"awb.h5\")\n",
    "else:\n",
    "    print(\"Training new model\\n\")\n",
    "    model_history = model.fit(train_image_for_train, ground_truth_train, epochs=40, batch_size=32, validation_data=(train_image_for_test, ground_truth_test))\n",
    "if not use_saved_model:\n",
    "    model.save(\"awb_test.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#visualkeras.layered_view(model,legend=True,scale_xy= 1.5).show()\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(model_history.epoch, model_history.history['loss'])\n",
    "plt.title('Epochs on Training Loss')\n",
    "plt.xlabel('# of Epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(model_history.epoch, model_history.history['accuracy'])\n",
    "plt.title('Epochs on Training accuracy')\n",
    "plt.xlabel('# of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_history.epoch, model_history.history['val_loss'])\n",
    "plt.title('Epochs on validation loss')\n",
    "plt.xlabel('# of Epochs')\n",
    "plt.ylabel('validation loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = model.predict(train_image_for_test)\n",
    "model.evaluate(result, ground_truth_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confusion matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.imshow(ground_truth_test[1])\n",
    "ax = plt.gca()\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Tinted image\")\n",
    "plt.imshow(train_image_for_test[1])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Unet\")\n",
    "plt.imshow(result[1])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gray World method for white balancing an image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/Bad/cat.4.jpg\")\n",
    "\n",
    "array = cv2.resize(img, (256, 256))\n",
    "array = (np.array(array))/255\n",
    "\n",
    "gw_result = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "avg_a = np.average(gw_result[:, :, 1])\n",
    "avg_b = np.average(gw_result[:, :, 2])\n",
    "gw_result[:, :, 1] = gw_result[:, :, 1] - ((avg_a - 128) )\n",
    "gw_result[:, :, 2] = gw_result[:, :, 2] - ((avg_b - 128) )\n",
    "gw_result = cv2.cvtColor(gw_result, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Tinted Image\")\n",
    "plt.imshow(train_image_for_test[2])\n",
    "plt.axis('off')\n",
    "#plt.show()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Gray world method\")\n",
    "plt.imshow(gw_result)\n",
    "plt.axis('off')\n",
    "#plt.show()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"CNN\")\n",
    "plt.imshow(result[2])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the original image and corrected image\n",
    "# Only for testing\n",
    "orig_img = cv2.imread('images/Good/cat.1.jpg')\n",
    "corr_img = cv2.imread('images/Bad/cat.1.jpg')\n",
    "\n",
    "# Convert the images to grayscale and resize them to the same size\n",
    "# Only for testing\n",
    "orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2GRAY)\n",
    "corr_img = cv2.cvtColor(corr_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "orig_img = cv2.resize(orig_img, (corr_img.shape[1], corr_img.shape[0]))\n",
    "\n",
    "#gw_result = cv2.resize(gw_result, (256, 256))\n",
    "# Compute the peak signal-to-noise ratio (PSNR) between the images\n",
    "mse = np.mean((train_image_for_test[2] - result[2]) ** 2)\n",
    "if mse == 0:\n",
    "    psnr = float('inf')\n",
    "else:\n",
    "    psnr = 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "# Print the PSNR value\n",
    "print('PSNR:', psnr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
